\section{Conclusions}
<TBD> \\ \\Draft: For scientific text summarization specifically, models need sufficient capacity to understand domain terminology and complex relationships without the computational overhead and potential overfitting of massive proprietary systems.  

The semantic comprehension and text generation strengths of general-purpose LLMs outweigh the multi-step reasoning capabilities that reasoning-oriented models bring to other domains
