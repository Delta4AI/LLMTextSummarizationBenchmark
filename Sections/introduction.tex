\section{Introduction}

The exponential growth of scientific literature has created a demand for text summarization methods to support scientists in efficiently prioritizing papers, extracting relevant information, and interpreting complex findings. \ac{ATS} methods have evolved from statistical approaches to deep learning-based models, becoming increasingly sophisticated and reliable at capturing essential parts from complex research articles. \ac{ATS} methods have been previously evaluated and described \cite{zhang2025comprehensivesurveyprocessorientedautomatic,zhang2024systematicsurveytextsummarization}, but few are tailored for scientific literature summarization \cite{ROHIL2022100058,xie2023surveybiomedicaltextsummarization}. 

\subsection{Statistical and Encoder-Decoder Approaches}

The pre-neural era of text summarization was mainly characterized by extractive approaches, where in an unsupervised way, summaries were generated by using word or concept frequencies to identify relevant sentences. The first word-frequency based approaches were discussed by Luhn \cite{Luhn1958TheAC}, who presented a method based on the assumption that recurrent words in a text are likely more important. Later, Edmundson \cite{10.1145/321510.321519} introduced concepts such as cue words, title words, and sentence position to further enhance the automatic summarization process. The concept of \ac{TF-IDF} was later adopted \cite{article} and applied to text summarization by representing sentences as term-weight vectors that down-weight frequently occurring terms with low context specificity in an entire corpus of documents, while promoting rarer terms that at the same time are more context-specific. Word-frequency based approaches have been extensively used in scientific text summarization, being at the basis of more sophisticated strategies \cite{10.1145/1183614.1183701}. Finally, graph-based statistical methods, in which sentences are represented as nodes and their relationships as edges weighted by similarity measures (e.g. cosine similarity of \ac{TF-IDF} vectors), allow for the identification of the most central information based on the documents global structure rather than local word counts. A widely used approach in the biomedical domain is TextRank, which constructs a sentence graph to then apply the PageRank algorithm to compute importance sentence importance scores, and generates the summary by selecting the top-ranked sentences \cite{mihalcea-tarau-2004-textrank}. 

With the advent of \ac{Seq2seq} frameworks, summarization shifted toward neural approaches that paraphrase and condense text using Encoder-Decoder architectures, originally implemented with \acp{RNN}, \ac{LSTM} networks, and \acp{GRU} \cite{afzal2020, almasoud2022}. The introduction of self-attention mechanisms replaced \ac{Seq2seq} frameworks by processing sequences in parallel rather than sequentially, enabling the capture of complex linguistic patterns and long-range contextual relationships \cite{vaswani2023attentionneed}. This innovation laid the foundation for transformer architectures that quickly gained popularity in performing a wide range of \ac{NLP} tasks, including text summarization. One of the earliest and most influential transformer-based models, \ac{BERT} \cite{devlin2019bertpretrainingdeepbidirectional}, was widely adopted in domain specific tasks owing to its possibility to be fine-tuned by adding a task-specific output layer. Inspired by \ac{BERT}'s architecture, several abstractive summarization models emerged, including \ac{BART} - a denoising autoencoder for pretraining \ac{Seq2seq} models \cite{DBLP:journals/corr/abs-1910-13461} that can be trained or fine-tuned on scientific literature \cite{yuan-etal-2022-biobart, abinaya2024}. The \ac{T5} model was introduced as a unified text-to-text framework for a broad spectrum of \ac{NLP} tasks due to its high flexibility with no need for architectural changes \cite{JMLR:v21:20-074}. \ac{PEGASUS}, was specifically proposed for abstractive summarization \cite{zhang2020pegasuspretrainingextractedgapsentences} and has been adapted for scientific text with domain-specific variants including “google/pegasus-pubmed” and “google/bigbird-pegasus-large-pubmed”. \ac{RoBERTa} is an optimized version of \ac{BERT} trained on a bigger corpus of text, which led to the creation of Longformer \cite{Beltagy2020Longformer}, a transformer-based architecture that can handle longer texts for text-to-text generation, with “allenai/led-base-16384” and “led-large-16384-arxiv” as notable examples \cite{steblianko2024}.

\subsection{Language Models}

Despite these advances, the field of \ac{ATS} quickly moved towards decoder-only architectures which are at the basis of \acp{LLM}, able to capture semantic relations with higher flexibility and specificity. \acp{LLM} can be classified as (i) general-purpose models, which leverage their broad domain knowledge across diverse \ac{NLP} tasks, (ii) reasoning-oriented models, characterized by logical text understanding through iterative chain-of-thought processing and instruction tuning \cite{plaat2025multistepreasoninglargelanguage}, and (iii) domain-specific models, tailored for specialized tasks or scientific domains. Several families of \acp{LLM} have been developed, including the \ac{GPT} series developed by OpenAI (GPT-1 \cite{Radford2018ImprovingLU} through GPT-5) and open-source variants like GPT:OSS, all pre-trained on large-scale text corpora through self-supervised learning. Similarly, Anthropic's Claude Models are built on transformer architecture and trained through a Constitutional AI approach \cite{bai2022constitutionalaiharmlessnessai}. This family also includes a series of reasoning models such as Sonnet-4 and Opus-4. Meta's \ac{Llama} family \cite{grattafiori2024llama3herdmodels}, with LLaMA 3.1 as the most capable open-source model available to date, includes domain-specific adaptations such as OpenBioLLM-LLaMA-3 \cite{OpenBioLLMs}, a biomedical variant trained on a large corpus of high-quality biomedical data, and MedLLaMA-2 \cite{touvron2023llama2openfoundation}, a medical \ac{LM} based on LLaMA 2 architecture. Google developed a series of lightweight models including the Gemma series \cite{gemmateam2025gemma3technicalreport}, with Gemma3 as its latest and most powerful reasoning model. Microsoft introduced the Phi series \cite{abdin2024phi3technicalreporthighly, abdin2024phi4technicalreport}, which comprises Phi-4-reasoning and Phi-4-mini-reasoning, alongside BioGPT \cite{10.1093/bib/bbac409}, a domain-specific model built on the \ac{GPT} architecture and fine-tuned for biomedical applications. IBM released the Granite series \cite{mishra2024granitecodemodelsfamily}, with Granite 4.0 as its reasoning-capable variant. Mistral AI developed the Mistral family \cite{jiang2023mistral7b}, including Magistral as its first reasoning model \cite{mistralai2025magistral}, and Biomistral \cite{labrak2024biomistral}, an open-source variant pretrained on PubMed Central data for biomedical text processing. Alibaba Cloud introduced the Qwen 3 series \cite{qwen3technicalreport} as an open-source LLM family, which inspired SciLitLLM \cite{li2025scilitllmadaptllmsscientific}, a specialized model for scientific literature understanding based on Qwen2.5 and trained through \ac{CPT} and \ac{SFT} on scientific literature \cite{li2025scilitllmadaptllmsscientific}. DeepSeek has developed \ac{RL}-driven reasoning models that achieve performance comparable to state-of-the-art closed-source models while requiring only a fraction of their training costs \cite{wang2025reviewdeepseekmodelskey}. Lastly, Apertus \cite{swissai2025apertus} represents Switzerland’s first large-scale open, multilingual \ac{LM} with a fully documented and openly accessible development process. 

To the best of our knowledge, no comprehensive benchmarking of text summarization models on biomedical literature has been reported to date. This study addresses this gap by systematically evaluating 62 summarization models, ranging from word-frequency methods to state-of-the-art \acp{LLM}, using a curated dataset of 1,000 biomedical abstracts and corresponding highlights sections as reference summaries for benchmarking. By identifying the strengths and limitations of each approach, we provide actionable insights for selecting appropriate summarization tools to accelerate knowledge discovery in biomedical sciences.  