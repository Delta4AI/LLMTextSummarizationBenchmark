[
  {
    "platform": "huggingface",
    "model": "facebook/bart-large-cnn",
    "training_cutoff": "2019",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/facebook/bart-large-cnn",
      "https://arxiv.org/abs/1910.13461"
    ],
    "notes": "Estimated. BART paper Oct 2019; pre-trained on books + news corpus collected through ~2019. Fine-tuned on CNN/DailyMail (articles up to ~2015).",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "facebook/bart-base",
    "training_cutoff": "2019",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/facebook/bart-base",
      "https://arxiv.org/abs/1910.13461"
    ],
    "notes": "Estimated. Same pre-training corpus as BART-Large (~2019).",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "google-t5/t5-base",
    "training_cutoff": "2019-04",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/google-t5/t5-base",
      "https://arxiv.org/abs/1910.10683"
    ],
    "notes": "Estimated. T5 pre-trained on C4, a cleaned Common Crawl snapshot from Apr 2019.",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "google-t5/t5-large",
    "training_cutoff": "2019-04",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/google-t5/t5-large",
      "https://arxiv.org/abs/1910.10683"
    ],
    "notes": "Estimated. Same pre-training corpus as T5-Base (C4, Apr 2019).",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "csebuetnlp/mT5_multilingual_XLSum",
    "training_cutoff": "2020",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum",
      "https://arxiv.org/abs/2106.13822",
      "https://arxiv.org/abs/2010.11934"
    ],
    "notes": "Estimated. mT5 pre-trained on mC4 (multilingual Common Crawl, ~2020). XL-Sum fine-tuning data collected from BBC through ~2020.",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "google/pegasus-xsum",
    "training_cutoff": "2020",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/google/pegasus-xsum",
      "https://arxiv.org/abs/1912.08777"
    ],
    "notes": "Estimated. PEGASUS pre-trained on C4 + HugeNews (web-crawled news, ~2019-2020).",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "google/pegasus-large",
    "training_cutoff": "2020",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/google/pegasus-large",
      "https://arxiv.org/abs/1912.08777"
    ],
    "notes": "Estimated. Same pre-training corpus as other PEGASUS variants (~2019-2020).",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "google/pegasus-cnn_dailymail",
    "training_cutoff": "2020",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/google/pegasus-cnn_dailymail",
      "https://arxiv.org/abs/1912.08777"
    ],
    "notes": "Estimated. PEGASUS pre-trained ~2019-2020, fine-tuned on CNN/DailyMail.",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "AlgorithmicResearchGroup/led_large_16384_arxiv_summarization",
    "training_cutoff": "2020",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/AlgorithmicResearchGroup/led_large_16384_arxiv_summarization",
      "https://arxiv.org/abs/2004.05150"
    ],
    "notes": "Estimated. Longformer Encoder-Decoder, initialised from BART and published Apr 2020. Fine-tuned on arXiv papers available at that time.",
    "release_date": "2022-10-19",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "google/pegasus-pubmed",
    "training_cutoff": "2020",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/google/pegasus-pubmed",
      "https://arxiv.org/abs/1912.08777"
    ],
    "notes": "Estimated. PEGASUS pre-trained ~2019-2020, fine-tuned on PubMed.",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface",
    "model": "google/bigbird-pegasus-large-pubmed",
    "training_cutoff": "2020",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/google/bigbird-pegasus-large-pubmed",
      "https://arxiv.org/abs/2007.14062"
    ],
    "notes": "Estimated. BigBird paper Jul 2020; PEGASUS backbone pre-trained ~2019-2020, fine-tuned on PubMed.",
    "release_date": "2022-03-02",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface:completion",
    "model": "microsoft/biogpt",
    "training_cutoff": "2021",
    "source": "estimated",
    "evidence_urls": [
      "https://huggingface.co/microsoft/biogpt",
      "https://arxiv.org/abs/2210.10341"
    ],
    "notes": "Estimated. BioGPT paper (Oct 2022) states pre-training on 15M PubMed abstracts up to 2021.",
    "release_date": "2022-11-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface:chat",
    "model": "swiss-ai/Apertus-8B-Instruct-2509",
    "training_cutoff": "2024-03",
    "source": "confirmed",
    "evidence_urls": [
      "https://github.com/swiss-ai/apertus-tech-report/blob/main/Apertus_Tech_Report.pdf",
      "https://huggingface.co/swiss-ai/Apertus-8B-Instruct-2509"
    ],
    "notes": "Knowledge cutoff March 2024 per Apertus Tech Report (system prompt section).",
    "release_date": "2025-09",
    "release_date_source": "model_name"
  },
  {
    "platform": "huggingface:chat",
    "model": "Uni-SMART/SciLitLLM1.5-7B",
    "training_cutoff": "2024",
    "source": "estimated",
    "evidence_urls": [
      "https://arxiv.org/abs/2408.15545",
      "https://github.com/QwenLM/Qwen2.5/issues/525",
      "https://huggingface.co/Qwen/Qwen2.5-7B",
      "https://huggingface.co/Uni-SMART/SciLitLLM1.5-7B"
    ],
    "notes": "Estimated ~early-to-mid 2024, inherited from Qwen2.5-Base (released Sep 2024, training data through ~early-mid 2024). CPT corpora (RedPajama v1 ~early 2023, scientific textbooks/papers) and SFT data (SciRIFF) predate the base model cutoff. SciLitLLM paper does not state an explicit cutoff.",
    "release_date": "2024-11-04",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface:chat",
    "model": "Uni-SMART/SciLitLLM1.5-14B",
    "training_cutoff": "2024",
    "source": "estimated",
    "evidence_urls": [
      "https://arxiv.org/abs/2408.15545",
      "https://github.com/QwenLM/Qwen2.5/issues/525",
      "https://huggingface.co/Qwen/Qwen2.5-7B",
      "https://huggingface.co/Uni-SMART/SciLitLLM1.5-14B"
    ],
    "notes": "Estimated ~early-to-mid 2024, inherited from Qwen2.5-Base (released Sep 2024, training data through ~early-mid 2024). CPT corpora (RedPajama v1 ~early 2023, scientific textbooks/papers) and SFT data (SciRIFF) predate the base model cutoff. SciLitLLM paper does not state an explicit cutoff.",
    "release_date": "2024-11-04",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface:chat",
    "model": "aaditya/OpenBioLLM-Llama3-8B",
    "training_cutoff": "2023-03",
    "source": "confirmed",
    "evidence_urls": [
      "https://huggingface.co/aaditya/OpenBioLLM-Llama3-8B"
    ],
    "notes": "Based on LLaMA 3 8B (knowledge cutoff Mar 2023), fine-tuned on medical data.",
    "release_date": "2024-04-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "huggingface:conversational",
    "model": "BioMistral/BioMistral-7B",
    "training_cutoff": "2023",
    "source": "estimated",
    "evidence_urls": [
      "https://arxiv.org/abs/2402.10373",
      "https://github.com/BioMistral/BioMistral",
      "https://huggingface.co/BioMistral/BioMistral-7B"
    ],
    "notes": "Estimated ~mid-to-late 2023. Base model Mistral 7B Instruct v0.1 (released Sep 2023, general knowledge ~mid-2023). CPT on PMC Open Access Subset (~1.47M documents, likely downloaded Q3-Q4 2023). Biomedical domain knowledge may be slightly more recent than general knowledge. Neither the BioMistral paper nor Mistral specify exact cutoff dates.",
    "release_date": "2024-02-14",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "deepseek-r1:1.5b",
    "training_cutoff": "2025-01",
    "source": "community_dataset",
    "evidence_urls": [
      "https://explodingtopics.com/blog/list-of-llms",
      "https://arxiv.org/abs/2501.12948",
      "https://huggingface.co/deepseek-ai/DeepSeek-R1",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"DeepSeek-R1\".",
    "release_date": "2025-01-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "deepseek-r1:7b",
    "training_cutoff": "2025-01",
    "source": "community_dataset",
    "evidence_urls": [
      "https://explodingtopics.com/blog/list-of-llms",
      "https://arxiv.org/abs/2501.12948",
      "https://huggingface.co/deepseek-ai/DeepSeek-R1",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"DeepSeek-R1\".",
    "release_date": "2025-01-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "deepseek-r1:8b",
    "training_cutoff": "2025-01",
    "source": "community_dataset",
    "evidence_urls": [
      "https://explodingtopics.com/blog/list-of-llms",
      "https://arxiv.org/abs/2501.12948",
      "https://huggingface.co/deepseek-ai/DeepSeek-R1",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"DeepSeek-R1\".",
    "release_date": "2025-01-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "deepseek-r1:14b",
    "training_cutoff": "2025-01",
    "source": "community_dataset",
    "evidence_urls": [
      "https://explodingtopics.com/blog/list-of-llms",
      "https://arxiv.org/abs/2501.12948",
      "https://huggingface.co/deepseek-ai/DeepSeek-R1",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"DeepSeek-R1\".",
    "release_date": "2025-01-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "gemma3:270M",
    "training_cutoff": "2024-08",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.google.dev/gemma/docs/core/model_card_3"
    ],
    "notes": "Knowledge cutoff August 2024 per Gemma 3 model card.",
    "release_date": "2025-02-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "gemma3:1b",
    "training_cutoff": "2024-08",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.google.dev/gemma/docs/core/model_card_3"
    ],
    "notes": "Knowledge cutoff August 2024 per Gemma 3 model card.",
    "release_date": "2025-02-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "gemma3:4b",
    "training_cutoff": "2024-08",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.google.dev/gemma/docs/core/model_card_3"
    ],
    "notes": "Knowledge cutoff August 2024 per Gemma 3 model card.",
    "release_date": "2025-02-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "gemma3:12b",
    "training_cutoff": "2024-08",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.google.dev/gemma/docs/core/model_card_3"
    ],
    "notes": "Knowledge cutoff August 2024 per Gemma 3 model card.",
    "release_date": "2025-02-20",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "granite3.3:2b",
    "training_cutoff": "2024-04",
    "source": "estimated",
    "evidence_urls": [
      "https://github.com/orgs/ibm-granite/discussions/18",
      "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
      "https://www.ibm.com/granite"
    ],
    "notes": "Knowledge cutoff April 2024. Granite 3.3 README attributes its dataset to ibm-granite/granite-3.0-language-models; additional training uses synthetic data from open-source LLMs (no new world-knowledge). Granite 3.0 cutoff confirmed April 2024 by IBM maintainer (GitHub discussion).",
    "release_date": "2025-04-09",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "granite3.3:8b",
    "training_cutoff": "2024-04",
    "source": "estimated",
    "evidence_urls": [
      "https://github.com/orgs/ibm-granite/discussions/18",
      "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
      "https://www.ibm.com/granite"
    ],
    "notes": "Knowledge cutoff April 2024. Granite 3.3 README attributes its dataset to ibm-granite/granite-3.0-language-models; additional training uses synthetic data from open-source LLMs (no new world-knowledge). Granite 3.0 cutoff confirmed April 2024 by IBM maintainer (GitHub discussion).",
    "release_date": "2025-04-09",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "llama3.1:8b",
    "training_cutoff": "2023-12",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.meta.com/blog/meta-llama-3-1/",
      "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md"
    ],
    "notes": "Knowledge cutoff December 2023.",
    "release_date": "2024-07-18",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "llama3.2:1b",
    "training_cutoff": "2023-12",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
      "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md"
    ],
    "notes": "Knowledge cutoff December 2023.",
    "release_date": "2024-09-18",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "llama3.2:3b",
    "training_cutoff": "2023-12",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
      "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md"
    ],
    "notes": "Knowledge cutoff December 2023.",
    "release_date": "2024-09-18",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "medllama2:7b",
    "training_cutoff": "2022-09",
    "source": "confirmed",
    "evidence_urls": [
      "https://huggingface.co/meta-llama/Llama-2-7b",
      "https://arxiv.org/abs/2307.09288"
    ],
    "notes": "Based on LLaMA 2 (Sep 2022 pre-training cutoff), fine-tuned on medical data.",
    "release_date": "2023-07-09",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "mistral:7b",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3",
      "https://arxiv.org/abs/2310.06825"
    ],
    "notes": "Mistral 7B v0.3. No official cutoff published.",
    "release_date": "2024-05-22",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "mistral-nemo:12b",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
      "https://mistral.ai/news/mistral-nemo"
    ],
    "notes": "Mistral Nemo 12B. No official cutoff published.",
    "release_date": "2024-07-17",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "mistral-small3.2:24b",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506"
    ],
    "notes": "Mistral Small 3.2. No official cutoff published.",
    "release_date": "2025-06-19",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "PetrosStav/gemma3-tools:4b",
    "training_cutoff": "2024-08",
    "source": "confirmed",
    "evidence_urls": [
      "https://ai.google.dev/gemma/docs/core/model_card_3",
      "https://huggingface.co/PetrosStav/gemma3-4b-it-tools"
    ],
    "notes": "Fine-tuned Gemma 3 4B. Base model knowledge cutoff August 2024 per Gemma 3 model card.",
    "release_date": "2025-04",
    "release_date_source": "manual"
  },
  {
    "platform": "ollama",
    "model": "phi3:3.8b",
    "training_cutoff": "2023-10",
    "source": "confirmed",
    "evidence_urls": [
      "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct",
      "https://arxiv.org/abs/2404.14219"
    ],
    "notes": "Cutoff date Oct 2023 per model card.",
    "release_date": "2024-04-22",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "phi4:14b",
    "training_cutoff": "2024-06",
    "source": "confirmed",
    "evidence_urls": [
      "https://huggingface.co/microsoft/phi-4",
      "https://arxiv.org/abs/2412.08905"
    ],
    "notes": "Cutoff date Jun 2024 per model card.",
    "release_date": "2024-12-11",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "qwen3:4b",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://huggingface.co/Qwen/Qwen3-8B",
      "https://qwenlm.github.io/blog/qwen3/"
    ],
    "notes": "Alibaba Qwen 3. No official cutoff published.",
    "release_date": "2025-04-27",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "qwen3:8b",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://huggingface.co/Qwen/Qwen3-8B",
      "https://qwenlm.github.io/blog/qwen3/"
    ],
    "notes": "Alibaba Qwen 3. No official cutoff published.",
    "release_date": "2025-04-27",
    "release_date_source": "huggingface_api"
  },
  {
    "platform": "ollama",
    "model": "gpt-oss:20b",
    "training_cutoff": "2024-06",
    "source": "community_dataset",
    "evidence_urls": [
      "https://build.nvidia.com/openai/gpt-oss-20b/modelcard",
      "https://arxiv.org/pdf/2508.10925v1",
      "https://ollama.com/library/gpt-oss",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"GPT-oss\".",
    "release_date": "2025-08-05",
    "release_date_source": "manual"
  },
  {
    "platform": "ollama",
    "model": "granite4:micro",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://www.ibm.com/new/announcements/ibm-granite-4-0-hyper-efficient-high-performance-hybrid-models",
      "https://www.ibm.com/granite"
    ],
    "notes": "IBM Granite 4. Cutoff not publicly documented.",
    "release_date": "2025-10-02",
    "release_date_source": "manual"
  },
  {
    "platform": "ollama",
    "model": "granite4:micro-h",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://www.ibm.com/new/announcements/ibm-granite-4-0-hyper-efficient-high-performance-hybrid-models",
      "https://www.ibm.com/granite"
    ],
    "notes": "IBM Granite 4. Cutoff not publicly documented.",
    "release_date": "2025-10-02",
    "release_date_source": "manual"
  },
  {
    "platform": "ollama",
    "model": "granite4:tiny-h",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://www.ibm.com/new/announcements/ibm-granite-4-0-hyper-efficient-high-performance-hybrid-models",
      "https://www.ibm.com/granite"
    ],
    "notes": "IBM Granite 4. Cutoff not publicly documented.",
    "release_date": "2025-10-02",
    "release_date_source": "manual"
  },
  {
    "platform": "ollama",
    "model": "granite4:small-h",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://www.ibm.com/new/announcements/ibm-granite-4-0-hyper-efficient-high-performance-hybrid-models",
      "https://www.ibm.com/granite"
    ],
    "notes": "IBM Granite 4. Cutoff not publicly documented.",
    "release_date": "2025-10-02",
    "release_date_source": "manual"
  },
  {
    "platform": "openai",
    "model": "gpt-3.5-turbo",
    "training_cutoff": "2021-09",
    "source": "confirmed",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-3.5-turbo"
    ],
    "notes": "Alias for gpt-3.5-turbo-0125. Knowledge cutoff Sep 2021.",
    "release_date": "2023-03-01",
    "release_date_source": "manual"
  },
  {
    "platform": "openai",
    "model": "gpt-4.1",
    "training_cutoff": "2024-06",
    "source": "confirmed",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-4.1"
    ],
    "notes": "gpt-4.1-2025-04-14. Knowledge cutoff Jun 2024.",
    "release_date": "2025-04-14",
    "release_date_source": "manual"
  },
  {
    "platform": "openai",
    "model": "gpt-4.1-mini",
    "training_cutoff": "2024-06",
    "source": "confirmed",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-4.1-mini"
    ],
    "notes": "gpt-4.1-mini-2025-04-14. Knowledge cutoff Jun 2024.",
    "release_date": "2025-04-14",
    "release_date_source": "manual"
  },
  {
    "platform": "openai",
    "model": "gpt-4o",
    "training_cutoff": "2023-10",
    "source": "confirmed",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-4o"
    ],
    "notes": "gpt-4o-2024-08-06. Knowledge cutoff Oct 2023.",
    "release_date": "2024-05-13",
    "release_date_source": "manual"
  },
  {
    "platform": "openai",
    "model": "gpt-4o-mini",
    "training_cutoff": "2023-10",
    "source": "confirmed",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-4o-mini"
    ],
    "notes": "gpt-4o-mini-2024-07-18. Knowledge cutoff Oct 2023.",
    "release_date": "2024-07-18",
    "release_date_source": "manual"
  },
  {
    "platform": "openai",
    "model": "gpt-5-nano-2025-08-07",
    "training_cutoff": "2024-05",
    "source": "community_dataset",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-5-nano",
      "https://platform.openai.com/docs/models",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"GPT-5 nano\".",
    "release_date": "2025-08-07",
    "release_date_source": "model_name"
  },
  {
    "platform": "openai",
    "model": "gpt-5-mini-2025-08-07",
    "training_cutoff": "2024-05",
    "source": "community_dataset",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-5-mini",
      "https://platform.openai.com/docs/models",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"GPT-5 mini\".",
    "release_date": "2025-08-07",
    "release_date_source": "model_name"
  },
  {
    "platform": "openai",
    "model": "gpt-5-2025-08-07",
    "training_cutoff": "2024-10",
    "source": "community_dataset",
    "evidence_urls": [
      "https://platform.openai.com/docs/models/gpt-5",
      "https://platform.openai.com/docs/models",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"GPT-5\".",
    "release_date": "2025-08-07",
    "release_date_source": "model_name"
  },
  {
    "platform": "anthropic",
    "model": "claude-3-5-haiku-20241022",
    "training_cutoff": "2024-04",
    "source": "confirmed",
    "evidence_urls": [
      "https://docs.anthropic.com/en/docs/about-claude/models"
    ],
    "notes": "Early Apr 2024 training data cutoff.",
    "release_date": "2024-10-22",
    "release_date_source": "model_name"
  },
  {
    "platform": "anthropic",
    "model": "claude-sonnet-4-20250514",
    "training_cutoff": "2025-03",
    "source": "confirmed",
    "evidence_urls": [
      "https://docs.anthropic.com/en/docs/about-claude/models"
    ],
    "notes": "Early Mar 2025 training data cutoff.",
    "release_date": "2025-05-14",
    "release_date_source": "model_name"
  },
  {
    "platform": "anthropic",
    "model": "claude-opus-4-20250514",
    "training_cutoff": "2025-03",
    "source": "confirmed",
    "evidence_urls": [
      "https://docs.anthropic.com/en/docs/about-claude/models"
    ],
    "notes": "Early Mar 2025 training data cutoff.",
    "release_date": "2025-05-14",
    "release_date_source": "model_name"
  },
  {
    "platform": "anthropic",
    "model": "claude-opus-4-1-20250805",
    "training_cutoff": "2025-03",
    "source": "community_dataset",
    "evidence_urls": [
      "https://web.archive.org/web/20250829090806/https://docs.anthropic.com/en/docs/about-claude/models/overview",
      "https://docs.anthropic.com/en/docs/about-claude/models",
      "https://github.com/HaoooWang/llm-knowledge-cutoff-dates"
    ],
    "notes": "From community dataset (HaoooWang/llm-knowledge-cutoff-dates). Original entry: \"Claude 4.1 Opus\".",
    "release_date": "2025-08-05",
    "release_date_source": "model_name"
  },
  {
    "platform": "mistral",
    "model": "mistral-medium-2505",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://docs.mistral.ai/getting-started/models/premier/"
    ],
    "notes": "Mistral Medium 3 (May 2025). Cutoff not publicly documented.",
    "release_date": "2025-05",
    "release_date_source": "model_name"
  },
  {
    "platform": "mistral",
    "model": "magistral-medium-2509",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://docs.mistral.ai/getting-started/models/premier/"
    ],
    "notes": "Magistral Medium (Sep 2025). Cutoff not publicly documented.",
    "release_date": "2025-09",
    "release_date_source": "model_name"
  },
  {
    "platform": "mistral",
    "model": "mistral-large-2411",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://docs.mistral.ai/getting-started/models/premier/"
    ],
    "notes": "Mistral Large 24.11. Cutoff not publicly documented.",
    "release_date": "2024-11",
    "release_date_source": "model_name"
  },
  {
    "platform": "mistral",
    "model": "mistral-small-2506",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://docs.mistral.ai/getting-started/models/premier/"
    ],
    "notes": "Mistral Small 3.2 (Jun 2025). Cutoff not publicly documented.",
    "release_date": "2025-06",
    "release_date_source": "model_name"
  },
  {
    "platform": "mistral",
    "model": "mistral-medium-2508",
    "training_cutoff": null,
    "source": "unknown",
    "evidence_urls": [
      "https://docs.mistral.ai/getting-started/models/premier/"
    ],
    "notes": "Mistral Medium 3 update (Aug 2025). Cutoff not publicly documented.",
    "release_date": "2025-08",
    "release_date_source": "model_name"
  }
]